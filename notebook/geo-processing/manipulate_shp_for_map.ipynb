{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This notebook loads : \n",
    "###  [x] the grid with 100m cell\n",
    "###  [x] select only cell from list in train test val , add that as argument: selected_grid\n",
    "###  [x] then load the tlm file , merge the classes, give english names\n",
    "###  [ ] then cut the tlm via the select 100x100m cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_path = '/home/valerie/data/rocky_tlm/footprint/aoiGrid100m.shp'\n",
    "csv_paths = [ '/home/valerie/Projects/Alps_LCC/data/split/'+x+'_dataset.csv' for x in ['train','val','test'] ]\n",
    "tlm_path = '/home/valerie/data/ace_Xiaolong/mask_shp/Label.shp'\n",
    "ace_label_path = '/home/valerie/data/ace_Xiaolong/mask_shp/Label_cut.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                   rbg                  dem                   mask  mainclass\n",
       " 0  26193_11033_rgb.tif  26193_11033_dem.tif  26193_11033_label.tif        9.0\n",
       " 1  26455_11059_rgb.tif  26455_11059_dem.tif  26455_11059_label.tif        1.0\n",
       " 2  25602_11133_rgb.tif  25602_11133_dem.tif  25602_11133_label.tif       10.0\n",
       " 3  25750_11179_rgb.tif  25750_11179_dem.tif  25750_11179_label.tif        1.0\n",
       " 4  25659_11101_rgb.tif  25659_11101_dem.tif  25659_11101_label.tif        1.0,\n",
       " 229535)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the file paths and read each CSV file into a DataFrame\n",
    "for file_path in csv_paths:\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames vertically (along rows)\n",
    "tile_ids = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Display or manipulate the concatenated DataFrame as needed\n",
    "tile_ids .head(),len(tile_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['26193_11033',\n",
       " '26455_11059',\n",
       " '25602_11133',\n",
       " '25750_11179',\n",
       " '25659_11101',\n",
       " '25725_10905',\n",
       " '26370_11461',\n",
       " '26420_10961',\n",
       " '26429_11456',\n",
       " '25899_10953']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_list = tile_ids[tile_ids.columns[0]]\n",
    "id_list = [x.replace('_rgb.tif', '') for x in id_list]\n",
    "id_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = gpd.read_file(grid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            ID                                           geometry\n",
       " 0  25733_10799  POLYGON ((2573300.000 1079900.000, 2573300.000...\n",
       " 1  25734_10797  POLYGON ((2573400.000 1079700.000, 2573400.000...\n",
       " 2  25734_10798  POLYGON ((2573400.000 1079800.000, 2573400.000...\n",
       " 3  25734_10799  POLYGON ((2573400.000 1079900.000, 2573400.000...\n",
       " 4  25735_10793  POLYGON ((2573500.000 1079300.000, 2573500.000...,\n",
       " 398921)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.head(),len(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            ID                                           geometry\n",
       " 1  25734_10797  POLYGON ((2573400.000 1079700.000, 2573400.000...\n",
       " 2  25734_10798  POLYGON ((2573400.000 1079800.000, 2573400.000...\n",
       " 3  25734_10799  POLYGON ((2573400.000 1079900.000, 2573400.000...\n",
       " 4  25735_10793  POLYGON ((2573500.000 1079300.000, 2573500.000...\n",
       " 5  25735_10794  POLYGON ((2573500.000 1079400.000, 2573500.000...,\n",
       " 229535)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the isin() method to filter the GeoDataFrame\n",
    "selected_grid =  grid[grid['ID'].isin(id_list)]\n",
    "selected_grid.head(),len(selected_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the unary_union method to merge all polygons into one\n",
    "merged_grid = selected_grid['geometry'].unary_union\n",
    "\n",
    "# Create a new GeoDataFrame with the merged polygon\n",
    "merged_grid = gpd.GeoDataFrame({'geometry': [merged_grid]}, crs='epsg:2056')\n",
    "\n",
    "# Save the merged GeoDataFrame as a Shapefile\n",
    "merged_grid.to_file('merged_grid.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['UUID', 'DATUM_AEND', 'DATUM_ERST', 'ERSTELL_J', 'ERSTELL_M',\n",
      "       'REVISION_J', 'REVISION_M', 'GRUND_AEND', 'HERKUNFT', 'HERKUNFT_J',\n",
      "       'HERKUNFT_M', 'OBJEKTART', 'REVISION_Q', 'UUID_2', 'DATUM_AE_1',\n",
      "       'DATUM_ER_1', 'ERSTELL_J_', 'ERSTELL_M_', 'REVISION_1', 'REVISION_2',\n",
      "       'GRUND_AE_1', 'HERKUNFT_2', 'HERKUNFT_1', 'HERKUNFT_3', 'OBJEKTART_',\n",
      "       'REVISION_3', 'CLASS', 'geometry'],\n",
      "      dtype='object') ['Gletscher' 'Schneefeld Toteis' 'Gebueschwald' 'Fels' 'Felsbloecke' nan\n",
      " 'Lockergestein' 'Stehende Gewaesser' 'Fels locker' 'Feuchtgebiet'\n",
      " 'Lockergestein locker' 'Wald' 'Wald offen' 'Gehoelzflaeche'\n",
      " 'Felsbloecke locker' 'Fliessgewaesser']\n"
     ]
    }
   ],
   "source": [
    "# Load your GeoDataFrame (replace 'your_file.geojson' with your actual file path)\n",
    "tlm = gpd.read_file(tlm_path)\n",
    "print (tlm.columns, tlm['OBJEKTART_'].unique() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to map old class labels to new ones\n",
    "class_mapping = {\n",
    "    'Gletscher':    'glacier',\n",
    "    'Schneefeld Toteis': 'glacier',\n",
    "    'Gebueschwald': 'forest',\n",
    "    'Wald': 'forest',\n",
    "    'Wald offen':   'forest',\n",
    "    'Gehoelzflaeche' :  'forest',\n",
    "    'Fels': 'bedrock',\n",
    "    'Fels locker':  'bedrock with grass',\n",
    "    'Felsbloecke': 'large blocks',\n",
    "    'Felsbloecke locker' : 'large blocks with grass',\n",
    "    'Lockergestein': 'scree',\n",
    "    'Lockergestein locker': 'scree with grass',\n",
    "    'Stehende Gewaesser': 'water',\n",
    "    'Feuchtgebiet': 'water',\n",
    "    'Fliessgewaesser':'water',\n",
    " #    np.nan:'bug',\n",
    "}\n",
    "\n",
    "# Replace the old class labels with the new ones\n",
    "\n",
    "tlm['OBJEKTART'] =   tlm['OBJEKTART'].replace(class_mapping)\n",
    "tlm['OBJEKTART_'] =   tlm['OBJEKTART_'].replace(class_mapping)\n",
    "tlm['class'] = tlm['OBJEKTART'].fillna(tlm['OBJEKTART_'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlm.to_file(tlm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CLASS', 'geometry', 'class'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "clean_tlm = tlm.drop(['UUID', 'DATUM_AEND', 'DATUM_ERST', 'ERSTELL_J', 'ERSTELL_M',\n",
    "       'REVISION_J', 'REVISION_M', 'GRUND_AEND', 'HERKUNFT', 'HERKUNFT_J',\n",
    "       'HERKUNFT_M', 'OBJEKTART', 'REVISION_Q', 'UUID_2', 'DATUM_AE_1',\n",
    "       'DATUM_ER_1', 'ERSTELL_J_', 'ERSTELL_M_', 'REVISION_1', 'REVISION_2',\n",
    "       'GRUND_AE_1', 'HERKUNFT_2', 'HERKUNFT_1', 'HERKUNFT_3', 'OBJEKTART_',\n",
    "       'REVISION_3', ], axis = 1, )\n",
    "print(clean_tlm.columns)\n",
    "\n",
    "# Save the modified GeoDataFrame to a new file (optional)\n",
    "clean_tlm.to_file(ace_label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['scree', 'bedrock', 'forest', 'glacier', 'water',\n",
       "       'scree with grass', 'bedrock with grass', 'large blocks',\n",
       "       'large blocks with grass'], dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tlm['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
